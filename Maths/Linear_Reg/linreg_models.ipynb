{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4701d485",
   "metadata": {},
   "source": [
    "\n",
    "# Régression linéaire — OLS, Ridge, Lasso\n",
    "\n",
    "Ce notebook rappelle les formules mathématiques et montre des exemples pratiques avec `scikit-learn`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f09106",
   "metadata": {},
   "source": [
    "\n",
    "## 1. OLS (moindres carrés ordinaires)\n",
    "\n",
    "\\[\n",
    "\\min_{\\beta_0,\\beta}\\; \\sum_{i=1}^n \\Big(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij}\\Big)^2\n",
    "\\]\n",
    "\n",
    "Solution fermée si \\(X^\\top X\\) inversible :  \n",
    "\\[\n",
    "\\hat\\beta_{\\text{OLS}} = (X^\\top X)^{-1} X^\\top y\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d390c230",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Ridge (régularisation L2)\n",
    "\n",
    "\\[\n",
    "\\min_{\\beta_0,\\beta}\\; \\sum_{i=1}^n \\Big(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij}\\Big)^2\n",
    "\\;+\\; \\lambda \\sum_{j=1}^p \\beta_j^2\n",
    "\\]\n",
    "\n",
    "- Plus λ est grand, plus les coefficients sont **réduits** vers zéro.\n",
    "- Aucun coefficient n'est exactement nul.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beec1f9",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Lasso (régularisation L1)\n",
    "\n",
    "\\[\n",
    "\\min_{\\beta_0,\\beta}\\; \\sum_{i=1}^n \\Big(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij}\\Big)^2\n",
    "\\;+\\; \\lambda \\sum_{j=1}^p |\\beta_j|\n",
    "\\]\n",
    "\n",
    "- Certains coefficients deviennent **exactement nuls** → sélection de variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "n, p = 200, 10\n",
    "X = rng.normal(size=(n, p))\n",
    "true_beta = np.array([2.0, 0.0, -1.5, 0.0, 1.2, 0.0, 0.8, 0.0, 0.0, 0.0])\n",
    "y = 1.5 + X @ true_beta + rng.normal(0, 1.0, size=n)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c366d1",
   "metadata": {},
   "source": [
    "## 4. Exemple OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbaa869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ols = make_pipeline(StandardScaler(), LinearRegression())\n",
    "ols.fit(X_train, y_train)\n",
    "y_pred = ols.predict(X_test)\n",
    "\n",
    "print(\"Coefficients OLS:\", np.round(ols[-1].coef_, 3))\n",
    "print(\"Intercept OLS:\", round(ols[-1].intercept_, 3))\n",
    "print(\"Test RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"Test R²:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244bc31",
   "metadata": {},
   "source": [
    "## 5. Exemple Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92343884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alphas = np.logspace(-3, 3, 30)\n",
    "ridge = make_pipeline(StandardScaler(), RidgeCV(alphas=alphas, scoring='neg_mean_squared_error'))\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "print(\"Alpha choisi:\", ridge[-1].alpha_)\n",
    "print(\"Coefficients Ridge:\", np.round(ridge[-1].coef_, 3))\n",
    "print(\"Intercept Ridge:\", round(ridge[-1].intercept_, 3))\n",
    "print(\"Test RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"Test R²:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bea90",
   "metadata": {},
   "source": [
    "## 6. Exemple Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97285f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alphas = np.logspace(-3, 0, 30)\n",
    "lasso = make_pipeline(StandardScaler(), LassoCV(alphas=alphas, max_iter=5000, cv=5, random_state=0))\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "print(\"Alpha choisi:\", lasso[-1].alpha_)\n",
    "print(\"Coefficients Lasso:\", np.round(lasso[-1].coef_, 3))\n",
    "print(\"Intercept Lasso:\", round(lasso[-1].intercept_, 3))\n",
    "print(\"Test RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"Test R²:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e4204",
   "metadata": {},
   "source": [
    "## 7. Comparaison visuelle des coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02cbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coef_ols = ols[-1].coef_\n",
    "coef_ridge = ridge[-1].coef_\n",
    "coef_lasso = lasso[-1].coef_\n",
    "indices = np.arange(len(coef_ols))\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(indices-0.2, coef_ols, width=0.2, label=\"OLS\")\n",
    "plt.bar(indices, coef_ridge, width=0.2, label=\"Ridge\")\n",
    "plt.bar(indices+0.2, coef_lasso, width=0.2, label=\"Lasso\")\n",
    "plt.xticks(indices, [f\"x{j+1}\" for j in indices])\n",
    "plt.ylabel(\"Coefficient\")\n",
    "plt.title(\"Comparaison des coefficients\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
