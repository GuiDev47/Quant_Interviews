{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c51aed",
   "metadata": {},
   "source": [
    "\n",
    "# Régression linéaire **univariable** — workflow complet\n",
    "\n",
    "Ce notebook montre, étape par étape :\n",
    "1. Génération (ou chargement) d'un jeu de données **(X, y)** univariable  \n",
    "2. **Visualisation** des points pour vérifier la linéarité  \n",
    "3. **Régression linéaire** avec `scikit-learn`  \n",
    "4. Récupération de l'**intercept** et de la **slope (pente)**  \n",
    "5. **Courbe ajustée** superposée aux points  \n",
    "6. Calcul des **erreurs** (résidus) et des **métriques** (MAE, MSE, RMSE, R²)  \n",
    "7. **Visualisations des résidus** (résidus vs X, histogramme)\n",
    "\n",
    "> Remarque : toutes les visualisations utilisent **matplotlib** (pas seaborn), un **seul graphique par figure**, et **couleurs par défaut**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 1) Générer des données linéaires avec bruit\n",
    "rng = np.random.default_rng(123)\n",
    "n = 120\n",
    "X = np.linspace(-3, 3, n).reshape(-1, 1)           # univariable => shape (n, 1)\n",
    "true_intercept = 2.0\n",
    "true_slope = 3.5\n",
    "noise = rng.normal(0.0, 1.0, size=n)\n",
    "y = true_intercept + true_slope * X[:, 0] + noise\n",
    "\n",
    "print(f\"True intercept: {true_intercept}, True slope: {true_slope}\")\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf28299",
   "metadata": {},
   "source": [
    "## 1) Visualiser les points pour juger la linéarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df02aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0], y)\n",
    "plt.title(\"Scatter plot de y vs X\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a0a55a",
   "metadata": {},
   "source": [
    "## 2) Régression linéaire avec scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X, y)\n",
    "intercept_hat = model.intercept_\n",
    "slope_hat = float(model.coef_[0])\n",
    "print(f\"Intercept estimé: {intercept_hat:.4f}\")\n",
    "print(f\"Slope (pente) estimée: {slope_hat:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326313c5",
   "metadata": {},
   "source": [
    "## 3) Superposer la droite ajustée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0], y, label=\"Données\")\n",
    "# Pour tracer la droite proprement, utilisons un X trié\n",
    "order = np.argsort(X[:, 0])\n",
    "X_ordered = X[order, 0]\n",
    "yhat_ordered = y_hat[order]\n",
    "\n",
    "plt.plot(X_ordered, yhat_ordered, label=\"Droite ajustée\")\n",
    "plt.title(\"Régression linéaire — ajustement\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y et y_hat\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e55f66",
   "metadata": {},
   "source": [
    "## 4) Résidus et métriques d'erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "residuals = y - y_hat\n",
    "mae = mean_absolute_error(y, y_hat)\n",
    "mse = mean_squared_error(y, y_hat)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y, y_hat)\n",
    "\n",
    "print(f\"MAE :  {mae:.4f}\")\n",
    "print(f\"MSE :  {mse:.4f}\")\n",
    "print(f\"RMSE : {rmse:.4f}\")\n",
    "print(f\"R²  :  {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a556db",
   "metadata": {},
   "source": [
    "## 5) Graphiques des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0], residuals)\n",
    "plt.axhline(0)\n",
    "plt.title(\"Résidus vs X\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Résidu (y - y_hat)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.hist(residuals, bins=20)\n",
    "plt.title(\"Histogramme des résidus\")\n",
    "plt.xlabel(\"Résidu\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc09f6c",
   "metadata": {},
   "source": [
    "\n",
    "### Notes d'interprétation\n",
    "\n",
    "- Un **nuage de points** approximativement aligné indique qu'un modèle linéaire est plausible.\n",
    "- La **droite ajustée** doit capturer la tendance générale.\n",
    "- Les **résidus** doivent être centrés autour de 0, sans structure particulière (pas de forme en U, pas de corrélation apparente avec X).\n",
    "- L'**histogramme des résidus** doit sembler (grossièrement) symétrique si l'hypothèse de bruit gaussien est raisonnable.\n",
    "- Les **métriques** (MAE, RMSE, R²) servent à quantifier la qualité d'ajustement.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
