{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0042ab74",
   "metadata": {},
   "source": [
    "\n",
    "# 4.1.4 ‚Äî Monte Carlo (bases) : martingale & mouvement brownien\n",
    "\n",
    "## üéØ Objectifs\n",
    "- Comprendre la **m√©thode de Monte Carlo** sur des fonctionnelles simples du **mouvement brownien** $W_t$.\n",
    "- V√©rifier num√©riquement des **identit√©s en loi** (martingale, normalit√©, variance).\n",
    "- Mettre en ≈ìuvre des **techniques simples** : antith√©tiques, estimation de l'erreur, convergence en $\\mathcal{O}(1/\\sqrt{M})$.\n",
    "- Savoir estimer des quantit√©s comme $\\mathbb{E}[f(W_T)]$ et des **probabilit√©s de franchissement** √©l√©mentaires.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Rappels : Brownien & martingale\n",
    "\n",
    "- $W_0=0$, incr√©ments ind√©pendants, $W_T\\sim \\mathcal{N}(0,T)$.\n",
    "- Martingales classiques :\n",
    "  - $W_t$ est martingale.\n",
    "  - $W_t^2 - t$ est martingale.\n",
    "  - $\\exp\\!\\big(\\lambda W_t - \\tfrac12 \\lambda^2 t\\big)$ est martingale (exponentielle de Dol√©ans).\n",
    "\n",
    "Nous allons **v√©rifier num√©riquement** quelques √©galit√©s d'esp√©rance avec Monte Carlo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dead7b",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Monte Carlo : $\\mathbb{E}[f(W_T)]$ et estimation d'erreur\n",
    "\n",
    "Pour $W_T\\sim \\mathcal{N}(0,T)$, on peut simuler directement $W_T=\\sqrt{T}\\,Z$ avec $Z\\sim\\mathcal{N}(0,1)$ et approximer\n",
    "$$\n",
    "\\mathbb{E}[f(W_T)] \\approx \\frac{1}{M}\\sum_{m=1}^M f(W_T^{(m)}).\n",
    "$$\n",
    "Erreur statistique $\\approx \\mathrm{SE} = \\hat{\\sigma}/\\sqrt{M}$.  \n",
    "On illustre la **convergence** quand $M$ augmente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def mc_E_f_WT(f, T=1.0, M=100_000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    WT = np.sqrt(T) * rng.standard_normal(M)\n",
    "    vals = f(WT)\n",
    "    mean = vals.mean()\n",
    "    se = vals.std(ddof=1)/np.sqrt(M)\n",
    "    return mean, se\n",
    "\n",
    "# Exemples : f(x)=x^2, f(x)=exp(x)\n",
    "for f in [\n",
    "    lambda x: x**2,\n",
    "    lambda x: np.exp(x),\n",
    "]:\n",
    "    m, se = mc_E_f_WT(f, T=1.0, M=200_000, seed=42)\n",
    "    print(\"MC mean‚âà\", m, \"  SE‚âà\", se)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e588b2",
   "metadata": {},
   "source": [
    "\n",
    "> **Remarque** : pour $f(x)=x^2$ et $T=1$, on sait que $\\mathbb{E}[W_1^2]=1$.  \n",
    "Pour $f(x)=e^x$, $\\mathbb{E}[e^{W_1}] = e^{1/2}$ (moment de la loi normale).  \n",
    "V√©rifiez la proximit√© avec l'estimation Monte Carlo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d5323",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Variance reduction : **antith√©tiques**\n",
    "\n",
    "Id√©e : si on simule $Z$ alors on simule aussi $-Z$ ; on moyenne $f(\\sqrt{T}Z)$ et $f(-\\sqrt{T}Z)$.  \n",
    "Souvent, cela **r√©duit la variance** (sym√©trie).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def mc_antithetic(f, T=1.0, M=100_000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Z = rng.standard_normal(M//2)\n",
    "    WT_plus = np.sqrt(T)*Z\n",
    "    WT_minus = -WT_plus\n",
    "    vals = 0.5*(f(WT_plus) + f(WT_minus))\n",
    "    mean = vals.mean()\n",
    "    se = vals.std(ddof=1)/np.sqrt(M//2)  # M/2 moyennes ind√©pendantes\n",
    "    return mean, se\n",
    "\n",
    "m1, se1 = mc_E_f_WT(lambda x: np.exp(x), T=1.0, M=200_000, seed=1)\n",
    "m2, se2 = mc_antithetic(lambda x: np.exp(x), T=1.0, M=200_000, seed=1)\n",
    "\n",
    "(m1, se1), (m2, se2)  # comparez les SE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aaf84e",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Martingales simples : tests num√©riques\n",
    "\n",
    "- $\\mathbb{E}[W_T]=0$\n",
    "- $\\mathbb{E}[W_T^2 - T]=0$\n",
    "- $\\mathbb{E}[\\exp(\\lambda W_T - \\tfrac12\\lambda^2 T)]=1$\n",
    "\n",
    "On v√©rifie au Monte Carlo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e467723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def test_martingales(T=1.0, M=200_000, lam=0.7, seed=2):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    WT = np.sqrt(T) * rng.standard_normal(M)\n",
    "    m1 = WT.mean()\n",
    "    m2 = (WT**2 - T).mean()\n",
    "    m3 = np.exp(lam*WT - 0.5*(lam**2)*T).mean()\n",
    "    return m1, m2, m3\n",
    "\n",
    "test_martingales()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48954b20",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Probabilit√© de franchissement (basique)\n",
    "\n",
    "Pour un **niveau** $a>0$, la probabilit√© $\\mathbb{P}(\\max_{0\\le s\\le T} W_s \\ge a)$ admet une formule (m√©thode de r√©flexion) :\n",
    "$$\n",
    "\\mathbb{P}(\\max_{0\\le s\\le T} W_s \\ge a) = 2\\,\\mathbb{P}(W_T \\ge a) = 2 \\big(1-\\Phi(a/\\sqrt{T})\\big).\n",
    "$$\n",
    "On v√©rifie num√©riquement via des trajectoires discr√®tes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def brownian_paths(n_paths=50_000, T=1.0, N=500, seed=3):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dt = T/N\n",
    "    dW = rng.normal(0.0, np.sqrt(dt), size=(n_paths, N))\n",
    "    W = np.cumsum(dW, axis=1)\n",
    "    W = np.hstack((np.zeros((n_paths,1)), W))\n",
    "    return W  # shape: (n_paths, N+1)\n",
    "\n",
    "def crossing_prob(a=1.0, T=1.0, n_paths=50_000, N=500, seed=3):\n",
    "    W = brownian_paths(n_paths, T, N, seed)\n",
    "    hit = (W.max(axis=1) >= a).mean()\n",
    "    return hit\n",
    "\n",
    "# Comparaison MC vs formule\n",
    "a, T = 1.0, 1.0\n",
    "mc = crossing_prob(a, T, n_paths=30_000, N=600, seed=4)\n",
    "from math import erf, sqrt\n",
    "import numpy as np\n",
    "def Phi(x):  # CDF N(0,1)\n",
    "    return 0.5*(1+erf(x/np.sqrt(2)))\n",
    "theo = 2*(1-Phi(a/np.sqrt(T)))\n",
    "mc, theo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f59ee",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üìå √Ä retenir\n",
    "- $W_T\\sim \\mathcal{N}(0,T)$ : on peut simuler **directement** sans trajectoire si on ne d√©pend que de $W_T$.\n",
    "- L‚Äôerreur MC d√©cro√Æt comme $\\mathcal{O}(1/\\sqrt{M})$ ; **antith√©tiques** aident souvent.\n",
    "- Tester des **martingales** est un bon sanity check.\n",
    "- Franchissement : formule simple via **r√©flexion** pour le Brownien standard.\n",
    "\n",
    "## ‚úçÔ∏è Exercices (simples mais importants)\n",
    "1. V√©rifier $\\mathbb{E}[\\exp(\\lambda W_T - \\tfrac12\\lambda^2T)]=1$ pour plusieurs valeurs de $\\lambda$ et $T$ ; tracer l‚Äôerreur vs $M$.  \n",
    "2. Impl√©menter une **borne de confiance** √† 95% sur l‚Äôestimateur MC.  \n",
    "3. Estimer $\\mathbb{E}[(W_T^+)^p]$ pour $p=1,2$ et comparer au calcul analytique (moment demi-normal).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
