{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d244dd8",
   "metadata": {},
   "source": [
    "\n",
    "# 03 ‚Äî Concurrence & Parall√©lisme en Python (Version **Universit√©**)\n",
    "\n",
    "> **Objectif p√©dagogique** : √† la fin de ce chapitre, tu dois √™tre capable d‚Äô**expliquer** (oral d‚Äôentretien) et **impl√©menter** (live coding) un pipeline concurrent **correct** en Python, choisir entre **threads**, **processus**, et **asyncio**, et justifier tes choix (I/O‚Äëbound vs CPU‚Äëbound, GIL, co√ªts de pickling, backpressure, timeouts).\n",
    "\n",
    "### Plan du cours\n",
    "1. **Motivation & vocabulaire** (concurrence vs parall√©lisme, latence vs d√©bit)  \n",
    "2. **Le GIL** (d√©finition, cons√©quences, mythes)  \n",
    "3. **Threading** (quand, pourquoi, design patterns : producer/consumer, backpressure, poison pill)  \n",
    "4. **Multiprocessing** (vrai parall√©lisme CPU, pickling, chunking, shared memory)  \n",
    "5. **Asyncio** (concurrence coop√©rative, event loop, cancellation, timeouts)  \n",
    "6. **√âtude de cas ‚Äúfeed ‚Üí strat√©gie ‚Üí OMS‚Äù** (combiner les mod√®les proprement)  \n",
    "7. **Pi√®ges, bonnes pratiques, checklist d‚Äôentretien**  \n",
    "8. **Exercices guid√©s** + corrig√©s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710440f",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Motivation & vocabulaire (5 min)\n",
    "\n",
    "**Pourquoi la concurrence ?**  \n",
    "Dans un moteur de trading, tu dois souvent **consommer** des donn√©es (ticks, carnets d‚Äôordres), **calculer** des signaux, et **√©mettre** des ordres **en parall√®le** pour minimiser la **latence** et maximiser le **d√©bit**.\n",
    "\n",
    "**Concurrence vs Parall√©lisme**  \n",
    "- **Concurrence** : organiser des t√¢ches qui se **chevauchent** dans le temps (pas n√©cessairement ex√©cut√©es en m√™me temps).  \n",
    "- **Parall√©lisme** : ex√©cuter **vraiment en m√™me temps** sur plusieurs c≈ìurs.  \n",
    "Python (CPython) offre les deux, via des **threads** (concurrence utile en I/O), des **processus** (parall√©lisme CPU) et **asyncio** (concurrence coop√©rative mono‚Äëthread).\n",
    "\n",
    "**Latence vs D√©bit**  \n",
    "- **Latence** = temps de r√©ponse pour une t√¢che unique.  \n",
    "- **D√©bit (throughput)** = nombre de t√¢ches trait√©es par unit√© de temps.  \n",
    "Un bon design doit pr√©ciser ce qu‚Äôon optimise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263426c",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Le GIL (Global Interpreter Lock) ‚Äî ce qu‚Äôil faut dire √† l‚Äôoral\n",
    "\n",
    "- Le **GIL** est un verrou global de l‚Äôinterpr√©teur **CPython** : √† un instant donn√©, **un seul thread** ex√©cute du **bytecode Python**.  \n",
    "- **Implication** : pour du **CPU pur** (boucles Python lourdes), les threads **n‚Äôacc√©l√®rent pas** (ils se partagent le GIL).  \n",
    "- **Mais** : les op√©rations **I/O** (r√©seau, disque) **lib√®rent** le GIL ‚Üí les threads peuvent **vraiment** se chevaucher en I/O (bon pour HTTP, sockets, DB).  \n",
    "- Beaucoup de libs natives (NumPy) ex√©cutent du C qui **lib√®re** le GIL pendant l‚Äôop√©ration : un thread peut alors d√©coupler Python‚ÜîC.\n",
    "\n",
    "**R√©sum√© d√©cidable**  \n",
    "- **I/O‚Äëbound** ‚Üí `threading` **ou** `asyncio`  \n",
    "- **CPU‚Äëbound** ‚Üí `multiprocessing` (ou Numba/Cython)\n",
    "\n",
    "**Mythes fr√©quents**  \n",
    "- ‚ÄúLe GIL emp√™che toute concurrence‚Äù ‚ùå Faux : il emp√™che seulement l‚Äôex√©cution **CPU Python** simultan√©e, pas l‚Äô**overlap d‚ÄôI/O**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f0b88",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Threading ‚Äî Producer/Consumer, backpressure, poison pill \n",
    "\n",
    "### Quand utiliser les **threads** ?\n",
    "- T√¢ches **I/O‚Äëbound** : lectures socket, appels r√©seau, √©criture disque, DB.  \n",
    "- Tu veux un mod√®le pragmatique, simple √† lire, sans d√©pendre de l‚Äôevent loop `asyncio`.\n",
    "\n",
    "### Pourquoi une **queue** ?\n",
    "- **D√©coupler** producteur(s) et consommateur(s).  \n",
    "- Impl√©menter une **r√©gulation (backpressure)** via `maxsize` : si les consommateurs ralentissent, le producteur **bloque** sur `put()`, √©vitant de saturer la m√©moire.  \n",
    "- Faciliter l‚Äô**arr√™t propre** via **poison pill** (sentinelle `None`).\n",
    "\n",
    "### Sch√©ma mental\n",
    "```\n",
    "[Producer(s)] --put()--> [ queue.Queue(maxsize=M) ] --get()--> [Consumer(s)]\n",
    "   ‚Üë backpressure si file pleine                  ‚Üë poison pill pour arr√™ter\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e923d1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,\n",
       " [(0, 0, 0.7405738344840216),\n",
       "  (1, 3, 0.2692098905282778),\n",
       "  (3, 2, 0.32296949252872076),\n",
       "  (2, 1, 1.1266421518297678),\n",
       "  (2, 7, 1.8436315658140712)])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Threading : pipeline robuste avec backpressure & poison pill\n",
    "import threading, time, queue, random\n",
    "\n",
    "q = queue.Queue(maxsize=200)    # r√©gulation\n",
    "results = []\n",
    "N_ITEMS = 2000\n",
    "\n",
    "def producer(n=N_ITEMS):\n",
    "    for i in range(n):\n",
    "        q.put((i, random.random()))  # bloque si maxsize atteint\n",
    "    for _ in range(4):               # 4 consommateurs => 4 pilules\n",
    "        q.put(None)                  # poison pill\n",
    "\n",
    "def consumer(cid):\n",
    "    while True:\n",
    "        item = q.get()               # bloque si vide\n",
    "        if item is None:\n",
    "            q.task_done()\n",
    "            break\n",
    "        i, x = item\n",
    "        # Travail I/O simul√©\n",
    "        time.sleep(0.0005)\n",
    "        results.append((cid, i, x*2))\n",
    "        q.task_done()\n",
    "\n",
    "threads = [threading.Thread(target=consumer, args=(k,)) for k in range(4)]\n",
    "for t in threads: t.start()\n",
    "producer()\n",
    "q.join()                             # attend le traitement complet\n",
    "for t in threads: t.join()\n",
    "\n",
    "len(results), results[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8410430",
   "metadata": {},
   "source": [
    "\n",
    "### Sections critiques & **race conditions**\n",
    "D√®s qu‚Äôon **partage** un √©tat (ex : un compteur), deux threads peuvent √©crire **en m√™me temps** ‚Üí **race condition**.\n",
    "\n",
    "**Rem√®de** : un **verrou** (`threading.Lock`) entourant la **plus petite** portion de code qui manipule l‚Äô√©tat (section critique).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5584902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# D√©monstration lock minimal\n",
    "import threading\n",
    "\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def incr(n=10000):\n",
    "    global counter\n",
    "    for _ in range(n):\n",
    "        # Prot√©ger seulement ce qui est n√©cessaire\n",
    "        with lock:\n",
    "            counter += 1\n",
    "\n",
    "threads = [threading.Thread(target=incr) for _ in range(8)]\n",
    "[t.start() for t in threads]\n",
    "[t.join() for t in threads]\n",
    "counter  # doit √™tre 80000 si tout va bien\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7635a2",
   "metadata": {},
   "source": [
    "\n",
    "**Bonnes pratiques Threading (√† citer)**\n",
    "- Pr√©f√©rer la **communication par messages** (queues) aux verrous sophistiqu√©s.  \n",
    "- Les traitements doivent √™tre **idempotents** (rejouables sans casser l‚Äô√©tat).  \n",
    "- G√©rer l‚Äô**arr√™t** (poison pill), les **timeouts** et la **journalisation** (logs).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c9a5a",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Multiprocessing ‚Äî vrai parall√©lisme CPU (12 min)\n",
    "\n",
    "### Quand utiliser **multiprocessing** ?\n",
    "- T√¢ches **CPU‚Äëbound** (calcul num√©rique pur en Python) qui ne b√©n√©ficient pas d‚Äôune lib C optimis√©e.  \n",
    "- Exploiter **plusieurs c≈ìurs** sans GIL partag√©.\n",
    "\n",
    "### Co√ªts/Contraintes\n",
    "- **Pickling** : les donn√©es √©chang√©es entre process sont **s√©rialis√©es** ‚Üí co√ªt non n√©gligeable.  \n",
    "- **Spawn/Fork** : lancement de process co√ªteux (surtout `spawn` sur Windows/macOS).  \n",
    "- Favoriser des **gros ‚Äúchunks‚Äù** de travail (coarse‚Äëgrained) pour amortir les co√ªts.\n",
    "\n",
    "### Exemple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from multiprocessing import Pool\n",
    "import math, time\n",
    "\n",
    "def cpu_heavy(n):\n",
    "    s=0.0\n",
    "    for i in range(10_000):\n",
    "        s += math.sqrt((i*n) % 97)\n",
    "    return s\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "with Pool(4) as p:\n",
    "    res = p.map(cpu_heavy, [10,11,12,13])\n",
    "elapsed = time.perf_counter()-t0\n",
    "len(res), f\"{elapsed:.3f}s\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ccd49",
   "metadata": {},
   "source": [
    "\n",
    "**Tips ‚Äúentretien‚Äù**\n",
    "- Les objets envoy√©s √† un worker doivent √™tre **picklables**.  \n",
    "- **Chunking** : grouper des t√¢ches plut√¥t que d‚Äôenvoyer 1 micro‚Äët√¢che = 1 message.  \n",
    "- En data science, voir aussi **shared_memory** (tableaux partag√©s) pour limiter les copies.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f98a2",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Asyncio ‚Äî Concurrence coop√©rative mono‚Äëthread (15 min)\n",
    "\n",
    "### Pourquoi **asyncio** ?\n",
    "- Des milliers de **petites I/O** concurrentes (HTTP, websockets) avec un **faible overhead**.  \n",
    "- Contr√¥le fin : **timeouts**, **cancellation**, **gather**/`TaskGroup` (3.11+).\n",
    "\n",
    "### Sch√©ma mental\n",
    "```\n",
    "          +-------------------+\n",
    "          |   Event Loop      |\n",
    "await --> |   planifie/ordonne| --> d'autres coroutines progressent\n",
    "          +-------------------+\n",
    "```\n",
    "\n",
    "**Id√©e cl√©** : √† chaque `await`, la coroutine **rend la main**. Si elle attend I/O, **une autre** peut avancer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38450731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Timeout global avec asyncio.wait_for + gather\n",
    "import asyncio, random\n",
    "\n",
    "async def fetch(symbol):\n",
    "    await asyncio.sleep(random.random()/5)  # I/O simul√©\n",
    "    return symbol, 100 + random.random()\n",
    "\n",
    "async def main():\n",
    "    syms = [f\"SYM{i}\" for i in range(10)]\n",
    "    try:\n",
    "        res = await asyncio.wait_for(\n",
    "            asyncio.gather(*[fetch(s) for s in syms]),\n",
    "            timeout=2.0\n",
    "        )\n",
    "        print(\"OK\", len(res))\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"Timeout global\")\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9948c87e",
   "metadata": {},
   "source": [
    "\n",
    "### Queue `asyncio` : producer/consumers\n",
    "- Tr√®s proche du mod√®le `queue.Queue`, mais **non bloquant**.  \n",
    "- Parfait pour un **collecteur de ticks** qui pousse dans un bus interne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e504b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import asyncio, random\n",
    "\n",
    "async def producer(ch, n=50):\n",
    "    for i in range(n):\n",
    "        await ch.put((i, random.random()))\n",
    "    for _ in range(3):\n",
    "        await ch.put(None)\n",
    "\n",
    "async def consumer(ch, cid):\n",
    "    while True:\n",
    "        item = await ch.get()\n",
    "        if item is None:\n",
    "            ch.task_done()\n",
    "            break\n",
    "        await asyncio.sleep(0.002)  # I/O simul√©\n",
    "        ch.task_done()\n",
    "\n",
    "async def run():\n",
    "    ch = asyncio.Queue(maxsize=20)\n",
    "    prod = asyncio.create_task(producer(ch, 100))\n",
    "    cons = [asyncio.create_task(consumer(ch, k)) for k in range(3)]\n",
    "    await asyncio.gather(prod)\n",
    "    await ch.join()\n",
    "    for c in cons:\n",
    "        await c\n",
    "\n",
    "asyncio.run(run())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a26450",
   "metadata": {},
   "source": [
    "\n",
    "**√Ä citer en entretien**\n",
    "- `await` = point de suspension coop√©ratif ; pas de pr√©emption.  \n",
    "- **Timeouts** via `asyncio.wait_for`, **cancellation** via `task.cancel()`.  \n",
    "- **Pas** de data race Python (mono‚Äëthread), mais attention au **partage mutable** entre coroutines.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b662a331",
   "metadata": {},
   "source": [
    "\n",
    "## 6) √âtude de cas : **Feed ‚Üí Strat√©gie ‚Üí OMS** (10 min)\n",
    "\n",
    "**Contexte** : tu re√ßois des ticks (I/O), tu calcules un signal (l√©ger CPU), tu routes un ordre (I/O).  \n",
    "**Design recommand√©** (simple & robuste) :\n",
    "```\n",
    "[Ticker Thread/Async] --(queue)--> [Strategy Worker(s)] --(queue)--> [OMS Adapter (I/O)]\n",
    "```\n",
    "- **Entr√©e** (I/O) : `threading` **ou** `asyncio`  \n",
    "- **Traitement** (l√©ger CPU) : **threads** conviennent (ou m√™me synchrone si simple)  \n",
    "- **Sortie** (I/O vers broker) : **Adapter** + `threading`/`asyncio`\n",
    "\n",
    "**Pourquoi pas `multiprocessing` ici ?**  \n",
    "- Le calcul est l√©ger. Co√ªts de **pickling** > gains.  \n",
    "- R√©serve `multiprocessing` aux t√¢ches **CPU lourdes** (pricing massif offline, backtests).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c00ad0",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Pi√®ges, bonnes pratiques, checklist d‚Äôentretien (8 min)\n",
    "\n",
    "**Pi√®ges classiques**\n",
    "- Oublier la **backpressure** (file non born√©e ‚Üí OOM).  \n",
    "- Pas de **poison pill** ‚Üí threads zombies √† l‚Äôarr√™t.  \n",
    "- Verrous trop larges ‚Üí **contention** + perf d√©grad√©e.  \n",
    "- Pas de **timeout** sur I/O ‚Üí blocages invisibles.  \n",
    "- M√©langer trop de mod√®les (threads + async + process) sans raison.\n",
    "\n",
    "**Bonnes pratiques**\n",
    "- **Simplicit√© d‚Äôabord** : un seul mod√®le si possible.  \n",
    "- **Messages/queues** > partage d‚Äô√©tat + verrous.  \n",
    "- **Idempotence** des handlers, **logs** clairs, **metrics** (latence, taille de file, d√©bit).  \n",
    "- Tests : **d√©terministes** (stubs pour I/O), pas de `sleep` arbitraires (utiliser des queues/√©v√©nements).\n",
    "\n",
    "**Checklist entretien (√† recaser)**\n",
    "- ‚ÄúGIL ‚áí threads pour I/O, `multiprocessing` pour CPU‚Äù  \n",
    "- ‚ÄúPipeline queue avec **maxsize** (backpressure) + **poison pill**‚Äù  \n",
    "- ‚Äú**Timeouts** & **cancellation** en `asyncio`‚Äù  \n",
    "- ‚Äú**Pickling** entre process, penser **chunking** / **shared_memory**‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec5be8",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Exercices guid√©s (avec corrig√©s)\n",
    "\n",
    "### Exercice A ‚Äî Pipeline threads avec mesure de d√©bit\n",
    "**T√¢che** : √©tends l‚Äôexemple ‚Äúproducer/consumer‚Äù pour afficher le **d√©bit (items/s)** et la **latence moyenne** par item.  \n",
    "**Indice** : timestamp √† la production + calcul √† la consommation.\n",
    "\n",
    "> üëâ Corrig√© ci‚Äëdessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ca067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Corrig√© Exercice A (simplifi√©)\n",
    "import time, threading, queue, statistics, random\n",
    "\n",
    "q = queue.Queue(maxsize=500)\n",
    "times = []\n",
    "N = 3000\n",
    "\n",
    "def prod():\n",
    "    for i in range(N):\n",
    "        q.put((i, time.perf_counter()))\n",
    "    for _ in range(4): q.put(None)\n",
    "\n",
    "def cons():\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if item is None:\n",
    "            q.task_done(); break\n",
    "        i, t0 = item\n",
    "        # Simule un petit travail\n",
    "        time.sleep(0.0003)\n",
    "        times.append(time.perf_counter()-t0)\n",
    "        q.task_done()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "ts = [threading.Thread(target=cons) for _ in range(4)]\n",
    "for t in ts: t.start()\n",
    "prod()\n",
    "q.join()\n",
    "for t in ts: t.join()\n",
    "elapsed = time.perf_counter()-t0\n",
    "throughput = N/elapsed\n",
    "lat = statistics.mean(times)\n",
    "throughput, lat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09391c37",
   "metadata": {},
   "source": [
    "\n",
    "### Exercice B ‚Äî `multiprocessing` avec chunking\n",
    "**T√¢che** : transforme une liste de 400 ‚Äújobs‚Äù en 8 chunks de 50 et distribue-les via `Pool.map`.  \n",
    "**But** : illustrer l‚Äôamortissement des co√ªts de messaging/pickling.\n",
    "\n",
    "*(√Ä faire en autonomie ‚Äî v√©rifie le temps total avec et sans chunking.)*\n",
    "\n",
    "### Exercice C ‚Äî `asyncio` + timeout par requ√™te\n",
    "**T√¢che** : lance 50 `fetch()` en parall√®le avec un **timeout par requ√™te** (pas juste global).  \n",
    "**Indice** : enveloppe **chaque** coroutine avec `wait_for` et g√®re `TimeoutError` **individuellement**.\n",
    "\n",
    "---\n",
    "\n",
    "## Glossaire express\n",
    "- **Backpressure** : m√©canisme qui ralentit la production quand la consommation ne suit pas.  \n",
    "- **Poison pill** : sentinelle pour arr√™ter proprement un worker.  \n",
    "- **Idempotence** : r√©p√©ter une action produit le m√™me √©tat final.  \n",
    "- **Pickling** : s√©rialisation Python pour IPC entre process.  \n",
    "- **Cancellation** : annuler une coroutine/Task en `asyncio`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
